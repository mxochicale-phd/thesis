@article{10.1371/journal.pone.0017696,


@article{rhea2011,
    author = {Rhea, Christopher K. AND Silver, Tobin A. AND Hong, S. Lee AND Ryu, Joong Hyun AND Studenka, Breanna E. AND Hughes, Charmayne M. L. AND Haddad, Jeffrey M.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Noise and Complexity in Human Postural Control: Interpreting the Different Estimations of Entropy},
    year = {2011},
    month = {03},
    volume = {6},
    url = {https://doi.org/10.1371/journal.pone.0017696},
    pages = {1-9},
    number = {3},
    doi = {10.1371/journal.pone.0017696}
}
    abstract = {Background Over the last two decades, various measures of entropy have been used to examine the complexity of human postural control. In general, entropy measures provide information regarding the health, stability and adaptability of the postural system that is not captured when using more traditional analytical techniques. The purpose of this study was to examine how noise, sampling frequency and time series length influence various measures of entropy when applied to human center of pressure (CoP) data, as well as in synthetic signals with known properties. Such a comparison is necessary to interpret data between and within studies that use different entropy measures, equipment, sampling frequencies or data collection durations.   Methods and Findings The complexity of synthetic signals with known properties and standing CoP data was calculated using Approximate Entropy (ApEn), Sample Entropy (SampEn) and Recurrence Quantification Analysis Entropy (RQAEn). All signals were examined at varying sampling frequencies and with varying amounts of added noise. Additionally, an increment time series of the original CoP data was examined to remove long-range correlations. Of the three measures examined, ApEn was the least robust to sampling frequency and noise manipulations. Additionally, increased noise led to an increase in SampEn, but a decrease in RQAEn. Thus, noise can yield inconsistent results between the various entropy measures. Finally, the differences between the entropy measures were minimized in the increment CoP data, suggesting that long-range correlations should be removed from CoP data prior to calculating entropy.   Conclusions The various algorithms typically used to quantify the complexity (entropy) of CoP may yield very different results, particularly when sampling frequency and noise are different. The results of this study are discussed within the context of the neural noise and loss of complexity hypotheses.},
