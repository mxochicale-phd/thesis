%*******************************************************************************
%****************************** Second Chapter *********************************
%*******************************************************************************
\chapter{Quantifying Movement Variability} \label{chapter2}

\section{Introduction}
It has been stated in Chapter \ref{chapter1} that movement variability can 
be modelled
and quantified with methods of nonlinear analysis mainly 
because
(i) the structures of the human physiology 
(e.g. lungs, neurons, etc.) suggest that many of their dynamics 
are controlled with nonlinear dynamics \citep{goldberger1990} 
and (ii) data from human movement can be noisy, deterministic, 
stochastic, non-stationary or deterministic-chaotic 
\citep{hatze1986, preatoni2010, preatoni2013, 
stergiou2006, newell1998, stergiou2011, caballero2014}.
Therefore, in this chapter fundamentals of time series, 
methods of nonlinear analysis to quantify movement variability 
and nonlinear analysis with real-world data are reviewed.

\section{Fundamentals of time-series analysis}
Biosignals from living systems can typically be 
noisy, deterministic, stochastic, non-linear, 
non-stationary or deterministic-chaotic \citep{klonowski2007, caballero2014, 
wijnants2009, gomezgarcia2014, stergiou2006, harbourne2009, stergiou2011,
hatze1986, newell1998}. That said, the following sections provide 
fundamental definitions of time series for this thesis.

\subsection{Linear and non-linear systems}
Linear systems are proportional or additive. For example, the interaction 
between variables of a linear system are negligible whereas for a nonlinear 
system such interaction of variables can produce emergent properties 
arising from the initial conditions of the system \citep{klonowski2007}.

\subsection{Stationary and non-stationary signals}
Stationary signals have the same mean and variance as time progress (e.g. 
a sinusoidal signal), however such stationary signal can also be changeable
(e.g. alternative sinusoidal signal).
In contrast, when statistics of the time series change with time then 
such a signal is known as non-stationary signal.
Non-stationary signals are therefore characterised by transients and 
drift over time. Examples of non-stationary signals are the time series of 
seasonal trends and changes \citep{kitagawa1984} or Electroencephalography (EEG) 
signals which present different and changeable intensity over time 
\citep{klonowski2007}.

\subsection{Deterministic and stochastic systems}
A deterministic system is predictable. Deterministic systems 
have a small number of variables of importance. 
Deterministic systems are hence modelled with linear ordinary 
differential equations and their initial conditions and constants.
In contrast, stochastic systems are non-predictable and therefore have 
more variables of equal importance and are typically  
modelled with probability theory \citep{klonowski2007}.

\subsection{Deterministic-chaotic time series}
Deterministic signals can dramatically change with a slight change 
of initial conditions and then after a long time-scale, the signal can 
appear to be stochastic \citep{amato1992}.
\citealt[p. 11]{klonowski2007} pointed out that "chaotic systems behave 
like they were stochastic but they are also deterministic", meaning that 
chaotic systems are predictable for a short time-scale but nonpredictable 
in a long time-scale because of the initial conditions of the systems. 
\citealt[p. 78]{preatoni2013}, in experiments in sport science, mentioned 
that "variability is likely to have both deterministic and a 
stochastic origin". It can then be assumed that time series for 
human body movement are neither independent nor stochastic but 
deterministic-chaotic \citep{stergiou2006, harbourne2009, stergiou2011}.

\section{Quantifying movement variability with nonlinear analysis}
Previous studies have shown that movement variability is not considered 
as a undesired factor that creates errors but a signature for 
assessment of healthiness (associated with unhealthy pathological states) 
or skillfulness (associated with the functionality of movement) 
\citep{stergiou2011}. 
That said, movement variability can fundamentally be either 
quantified based on 
(i) the magnitude of the variability or 
(ii) the dynamics of the variability \citep{caballero2014}. 
However, finding 
the appropriate methods to quantify movement variability is 
still an open problem. 

For instance, \cite{preatoni2010, preatoni2013} point
out that conventional statistics (e.g. standard deviation, coefficient 
of variation, intra-class correlation coefficient) only quantify 
the overall variability.
Also, \cite{stergiou2011} stated that statistical tools 
(e.g. mean, standard deviation and range) are a measure of centrality,
meaning such metrics are compared around a central point. Similarly, 
\cite{coffey2011} pointed out that the use of means and standard deviations 
led to reduction of data and therefore information is discarded.

Additionally, one can apply frequency-domain tools to quantify movement 
variability.
For example, \cite{hatze1986} proposed a measure of dispersion to 
quantify the deviation of motion from a certain reference using the 
Fourier series. However, deviations of motion are from angular coordinates 
(radians) and linear coordinates (meters) which made them an unacceptable 
fusion of variables. 
\cite{vaillancourt2001} pointed out that it is rare for frequency and 
amplitude to differ in postural tremor of patients with Parkinson's disease
but differences in time-dependent structures are apparent, and associated with 
a change of regularity of postural tremor.
\cite{klonowski2002, klonowski2007, klonowski2009} stated that 
frequency-domain tools require stationary data, otherwise using 
other type of data might create misleading results.

Applying either statistical tools or frequency-domain tools 
to quantify movement variability might create misleading results, 
specially when dealing with deterministic-chaotic signals
\citep{amato1992, dingwell2000, dingwell2007, miller2006}.
%%
%%ADD SURROGATE with is explained in dingwell* and miller
%%
Hence, the properties of deterministic-chaotic signals  
are aligned with the subtle changes in the neuro-muscular-skeletal system 
are caused by influences of environmental changes, training or latent 
pathologies \citep{preatoni2010, preatoni2013}
and that movement variability involves evolution of human movement and 
the exploratory nature of movement \citep{stergiou2011, caballero2014}. 
That said, \cite{stergiou2011, preatoni2010, caballero2014} 
highlighted that movement variability can be better described and quantified 
with different methods of nonlinear analysis such as: 
largest Lyapunov exponent \citep{bruijn2009, donker2007, kurz2010b, 
yang2011},
fractal analysis \citep{delignleres2003},
entropy rate \citep{cavanaugh2010},
Sample Entropy (SampEn)  \citep{richman2000, donker2007, liao2008, 
stins2009, vaillancourt2004},
Approximate Entropy (ApEn) \citep{pincus1991, kurz2010a, sosnoff2006, 
sosnoff2009, cavanaugh2010},
Fuzzy Entropy (FuzzyEn) \citep{chen2007},
Multiscale Entropy (MSE) \citep{costa2002},
Permutation Entropy (PE) \citep{bandt2002, vakharia2015},
Quadratic Sample Entropy (QSampEn) \citep{lake2011},
Amplitude-aware permutation entropy (AAPE) \citep{azami2016},
Detrended Fluctuation Analysis (DFA) \citep{gates2007, gates2008, 
hausdorff200} and 
Recurrence Quantification Analysis (RQA) \citep{zbilut1992, trulla1996, 
marwan2008}.

Having so many nonlinear tools to measure movement variability (MV) 
led \citealt[p. 67]{caballero2014} to raise the following question: 
"Is there a best tool to measure variability?" which lead me to ask
two questions for this thesis: (i) what to quantify in movement variability? 
and (ii) which tools are appropriate to quantify movement variability?

\subsection{What to quantify in movement variability?} \label{what_to_measure_with_MV}
Complexity for this thesis refers to the dynamics of 
joint biomechanical degrees of freedom of a person 
performing a task in a certain environment \citep{davids2003}.
That said, \cite{vaillancourt2002, vaillancourt2003} 
stated that there is no universal 
increase or decrease in complexity for movement variability as a function 
of age or disease 
but a dependency with the task dynamics. For example, in a constant-force 
task (where the task dynamics is of low dimension), older adults 
present less complexity due their inability to introduce additional degrees 
of freedom in the neuromuscular system. 
However, when the task dynamic is oscillatory,
older adults or unhealthy adults 
(having intrinsic low dimension dynamics of their resting state)
present an increase of complexity because these adults have more 
difficulty to reduce the dimension output to a lower dimension. 
In contrast, inspired by \cite{tononi1998} who modelled complexity
with the variables of complexity versus regularity of neural networks,
\cite{stergiou2006} proposed a model for optimal human movement variability
with the variables of complexity versus predictability.
The model of \cite{stergiou2006} stated that higher values of complexity are 
associated with rich behaviour of movements,
while lower values of complexity movements 
are associated with poor behaviours of movements.
%being too rigid or too unstable. 
Hence, higher complexity of movements are characterised by 
chaotic systems, while lesser complexity of movement is 
characterised either as noisy systems or periodic systems 
(having either low or high amounts of predictability) \citep{stergiou2006}.

Considering the works of \cite{vaillancourt2002, vaillancourt2003}, 
\cite{tononi1998} and \cite{stergiou2006}, 
I assume that the quantification of movement 
variability can be based on the complexity and predictability 
of human movement.

\subsection{Which methods of nonlinear analysis are appropriate to quantify 
movement variability?} 
\label{which_NT_are_appropriate_to_measure_MV}
\cite{stergiou2006} proposed a model for movement variability
which state that variables of complexity and predictability of a system 
can be used to characterise and quantify movement variability.
With that in mind, this thesis has led me to understand 
other challenges such as  
(i) finding, (ii) understanding and (iii) applying the appropriate  
methods of nonlinear analysis that can measure such variables.

\cite{pincus1991, pincus1995} proposed Approximate Entropy (ApEn) 
to quantify regularity of time series.
Then, \cite{richman2000} due to self-matching found that the algorithm 
of ApEn could evoke the occurrence of ln(0) which made ApEn dependant 
on the available 
data for which Sample Entropy (SampEn) was proposed as an algorithm that 
does not consider self-matching. 
Hence, SampEn values are independent of the length of time series and its 
algorithm is simpler than ApEn.
Then, instead of using single statistics, \cite{costa2002} proposed 
Multiscale Entropy (MSE) which computes SampEn of consecutive 
coarse-grained time series of the original time series defined by the 
scale factor.
With MSE algorithm, \citep{costa2002} noted that 
pathology dynamics for time series of heartbeat intervals 
are associated with reduction of complexity.
Therefore, \citealt[p. 3]{costa2002} concluded that physiological complexity 
is associated with the adaptive capacity of the organism,  
disease states and aging which "may be defined by a sustained
breakdown of long-term correlations and loss of information".
Essentially, entropy measures (AppEn and SampEn), 
quantify regularity and complexity of time series \citep{preatoni2013}.
However, \cite{goldberger1996} mentioned that the increase of irregularity 
in time series is not synonymous of increase with physiological complexity.
Similarly, an increase of ApEn or SampEn, "implying increase of irregularity 
and decrease in predictability" \cite[p. 25]{goldberger2002b}, is not 
synonymous with an increase of dynamical complexity when analysing physiology 
signals \citep{costa2002}.
Hence, \cite{goldberger2002b} demonstrated that ApEn as a regularity 
statistic is not a direct index of physiological complexity where, for example, 
a randomised time series of an healthy heartbeat with multi-scale and 
complex patterns of variability show a higher value of ApEn even though  
the time series is less complex. Therefore, \citealt[p. 24]{goldberger2002b} 
concluded that the loss of physiological complexity can be 
"better assessed using other measures which can detect and quantify the 
presence of long-term correlations in non-stationary series."
Hence, \cite{goldberger2002b, vaillancourt2002, costa2002} concluded that
ApEn and SampEn do not necessary show the right representation of what 
they intend to measure. 

Therefore, considering the previous cons of ApEn, SampEn and MSE, Detrended 
Fluctuation Analysis (DFA) can tackle the problem of quantifying 
long-term correlations of time series \citep{peng1995}.
DFA is based on analysing fractal features and is calculated 
as the root mean square fluctuation of an integrated 
and detrended time series and it is represented by a scaling exponent, 
$\alpha$, which is an indicator for roughness of time series,
e.g. "the larger the value of $\alpha$, the smoother the time series 
\citep[p. 83]{peng1995}.
However, DFA can result in a false conclusion for long-term 
correlations in the time series \cite[p. 5001]{rangarajan2000}, therefore 
DFA "can falsely classify certain type of time series as fractals" 
\cite[p. 80]{wijnants2009}.
With that in mind, \cite{wijnants2009} proposed the use of 
Recurrence Quantification Analysis (RQA) as a 
technique that does not present constraints with 
regards to length size, stationary or statistical distribution 
of the time series.
\cite{wijnants2009} also highlighted that SampEn index is computed 
over the sequential values of the time series, whereas Shannon entropy with  
RQA, RQAEn, is computed over the distribution of deterministic lines in 
the Recurrence Plots (RP) \citep{marwan2008, trulla1996, zbilut1992}.
Similarly, \cite{rhea2011} highlighted that algorithms to compute entropy 
measures are different since ApEn and SampEn are approximations of the 
Kolmogorov-Sinai Entropy computing the likelihood that a template pattern 
repeats in the time series while RQAEn is derived from Shannon entropy 
and is computing number of line segments of varying length in the RP.
Even with those differences in the algorithms, smaller values of 
recurrence percentage of the RQA show the increase on practice of movement
dynamics, concluding that such recurrence percentage indicate an 
increase of system stability \citep{wijnants2009}.

Another method to measure variability is the largest Lyapunov exponent (LyE) 
which is used to "quantify the rate at which nearby trajectories
converge or diverge" \citep[p. 85]{stergiou2016b}.
For instance, "LyE from a stable system with little to no divergence will 
be zero (e.g. sine wave)" and "LyE for an unstable system that has highest 
amount of divergence will be positive and relative high in value
(e.g. 0.469 for random noise)" and for chaotic systems like the Lorenz system,
LyE is in between the two of the previous extremes (LyE$\approx0.1$) 
\cite[p. 2874]{miller2006}. 

Measuring human movement variability requires a combination of the 
pros and cons of the previous methods that analyse either 
(i) the dynamic complexity or (ii) the degree of regularly, stability or 
predicability in a system \citep{goldberger2002b, harbourne2009, stergiou2011}.
For instance, \cite{rangarajan2000} stated 
the use of both spectral analysis 
and random walk analysis, the base of DFA, is a better approach than only 
using one method because, for instance, using only DFA can lead to 
false conclusion for long-term correlations in the time series.
Similarly, \cite{wijnants2009} selected different methods 
(e.g. spectral analysis, standard dispersion analysis, DFA, RQA and SampEn) 
to quantify movement variability that can complement the strengths of 
some of them and compensate the weakness of others. 
Recently, \cite{caballero2014} proposed 
the unification of different methods of nonlinear analysis 
to address every aspect of the dynamics 
of a systems and the characterisation of movement variability. 
Although, there is no best method to measure movement variability and an 
unification of methods to quantify human movement variability is still an 
open question \citep{caballero2014}, 
finding the appropriate method of nonlinear analysis 
to measure movement variability for a specific problem, and 
knowing its strengths and weakness of such appropriate method 
is one of the research questions for this thesis. 

\section{Nonlinear analysis with real-world data} \label{nonlieaRealdata} 
Recently, \cite{huffaker2017} pointed out that one of the caveats 
when applying methods of nonlinear time series analysis is its unreliability 
when the estimated metrics come from real-world data which are generally 
short, noisy and non-stationary. Similarly, \cite{preatoni2013} mentioned 
the limitations of methods of nonlinear analysis in sport activities 
where data required to be large (e.g. number of trials, duration of the 
experiment and sampling frequency). 
\cite{caballero2014} argued that there are weaknesses of different 
methods of nonlinear analysis regarding the characteristics 
of the time series such as non-stationarity, length data size, noise, 
sampling rate.
However, in the work of \cite{huffaker2017}, \cite{preatoni2013} and
\cite{caballero2014} no further exploration of the metrics of nonlinear
analysis with real-world data is presented.

\subsection{Non-stationarity}
Non-stationarity of time series signals might create
spurious increase or decrease in methods of nonlinear analysis. 
For instance, \cite{costa2007} noted that non-stationarity in 
the signals might alter the increase of irregularity of signals 
for the shortest scales when applying MSE.  
Also, \cite{dingwell2000} reported non-stationarity in time series 
when using LyE, where LyE requires to be validated using 
surrogation \citep{dingwell2000, miller2006}
to ensure the robustness of the metric. 
\cite{caballero2014} reported three options when dealing with 
non-stationary data: (i) remove non-stationary data, (ii) use empirical mode 
decomposition (EMD), or (iii) apply nonlinear tools, such as DFT and RQA, 
which are less sensitive to non-stationary data.

To remove non-stationary data, \cite{carroll1993} suggested 
to remove the trends or to eliminate the initial data 
(e.g. first 20 seconds of samples) 
to ignore the trend of time series.
For instance, \cite{vandieen2010}, in experiments with center of pressure movements 
in seated balancing, discarded the first 5 seconds of the time series 
in the start of the measurement.

Non-stationary time series can also be treated with Empirical Mode 
Decomposition (EMD) method which decompose nonlinear, non-stationary signals 
into their intrinsic frequency components \citep{huang1998, wu-huang2004, 
wu-huang2009}. Hence, \cite{flandrin2004, costa2007} tested whether EMD is a 
robust method for detrending and denoising time series and noted that 
 EMD does not require selection of input parameters. However, the reliability 
of EMD methods is still an open problem. For instance, an extension of EMD 
called Multivariate Empirical Mode Decomposition (MEMD) has been proposed 
to analyse multiple time series \citep{rehman2010, mandic2013}.
See \citep{wu-hu2006, costa2007, daubechies2011, bonnet2014, mert2018}
for applications of EMD.

Finally, one can use methods of nonlinear analysis that are unaffected 
by non-stationarity of time series such as 
Detrended Fluctuation Analys (DFA) \citep{hausdorff1995}
and Recurrence Quantification Analysis (RQA) \citep{zbilut1992, trulla1996, 
marwan2008}. 
However, \cite{bryce2012} reported negatives of DFA such as the introduction
of uncontrolled bias, computational expensiveness and highlighted  
that DFA cannot provide a generic protection against the non-stationarities 
of the signals. The implication of this review is that RQA
remains a promising approach. 

\subsection{Data length}
Many of the methods of nonlinear analysis are sensitive to the length of
time series \citep{caballero2014}.
For example, given that Multiscale Entropy (MSE) is a  
statistical measure, the data lengths when using MSE are recommended 
to be large (e.g. up to the scale of $6 \times 10^3$ data points) 
to ensure enough samples for the analysis \citep{costa2007}. 
Also, the methods of LyE \citep{wolf1985}, DFA \citep{peng1995}, 
SampEn \citep{rhea2011} and ApEn \citep{richman2000} 
require a minimum of data length whereas 
FuzzyEn \citep{chen2007} is more robust for data length.
However, the methods of RQA \citep{webber1994, riley1999, wijnants2009}
and Permutation Entropy \citep{zunino2009} are less sensitive 
to the length of time series.

\subsection{Sampling rate}
One possible solution for the sensitivity of nonlinear methods 
to data length is the increase or decrease of sampling rate \citep{caballero2014}.
However, \citealt[p. 267]{duarte2008} stated "the increase of sampling rate 
frequency would only increase artificially the data points without 
adding information" which raises the problem of 
oversamping signals. 
Then, \cite{rhea2011} investigated the influence of sampling rate in 
three entropy measures (ApEn, SampEn and RQAEn) concluding that
ApEn and RQAEn were robust across to the increase of sampling frequency,
while SampEn presented significant difference across all sampling 
frequencies. \cite{rhea2011} noted that SampEn is more sensitive to 
coliniarities than ApEn and RQAEn at higher frequencies which lead to a 
decrease of SampEn. \cite{rhea2011} then concluded that signals at 
higher frequencies appear to be more regular due to the increase of data, 
therefore producing erroneous entropy results.
\cite{caballero2013} stated that for short length time series
for SampEn and DFA, the decrease of sampling rate frequency is recommended 
because it presents less consumption of computational power.
Additionally, \cite{caballero2013} showed the robustness of the methods 
of SampEn and DFA when using different sampling rate frequencies, 
stating that frequencies near the dynamics of the activity 
create a more reliable analysis of the dynamics.
%with DFA values.
%and tested the statement of \cite{duarte2008} 
%that increasing the sampling rate do not increase the gain of information.

\subsection{Noise}
\cite{caballero2014} reviewed methods of nonlinear analysis 
that are affected by noise.
\cite{rosenstein1993}, for instance, tested the robustness of LyE against 
three levels of noise (lowest, moderate and highest) in order to note 
the unreliability of LyE exponents in high-noise environments.
However, such case of unreliability of LyE is unreal as the reported 
values of signal-to-noise ratios are substantially lower than those 
used at the experiments of \cite{rosenstein1993}.
\cite{bandt2002} proposed Permutation Entropy (PeEn) which is
an appropriate method for chaotic time series in the present of 
observational and dynamical noise.
Another example is the work of \cite{chen2009} who compared the 
robustness of FuzzEn, ApEn and SampEn metrics against different levels of noise, 
concluding that for a large value of the parameter $r$ of ApEn and SampEn, 
these two metrics can work well with high levels of noise, however
when noise increases, ApEn and SampEn fail to distinguish time series with 
different levels of noise, whereas FuzzEn is robust to such highest 
levels of noise.

Regardless of the source of noise which can either be mechanical 
(due to recording equipment) or physiological (due to different neural noise), 
\cite{rhea2011} highlighted the importance of the effects on noise in three 
entropy measures (ApEn, SampEn and RQAEn) which produce different results.
Values for AnEn and SampEn, for instance, tended to increase as noise was 
added to the signals, while RQAEn  showed an inverse effect, e.g. RQAEn 
values decreased as noise in the signal was increased.
Similar results for synthetic data were also reported by \cite{pellecchia2005} 
where RQAEn values decreased from ($RQAEn \approx 5$) for Lorenz system to a 
($RQAEn \approx 2$) for a periodic signal with a further decrease 
($RQAEn \approx 0.3$) for a sinusoid signal with superimposed noise. 
Therefore, RQA can be affected by noise \citep{rhea2011}.
However, the effects of noise and non-stationarity
can be mitigated with the selection of the right parameters to perform RQA,
particularly, using embedding dimensions from 10 to 20 
\citep{webber2005}.

Another solution for noisy time series is the use of 
traditional filtering methods. However, the attenuation of all frequencies 
of the signal along the with the noise, given a cutoff frequency, can cut 
out information that might be useful for nonlinear time-series. 
Another option is apply DFA, which additionally to the remove of local 
trends, it also reduces the noise of the signal \citep{hausdorff1995}.
Alternatively, filtering strategies for nonlinear time-series data can 
be applied which tailor in a more effective way the properties of 
nonlinear dynamics (see \citealt*{bradley2015} and references therein).


\section{Final remarks}
In this chapter, literature has been reviewed based on the questions of:
(i) what to quantify in movement variability, 
(ii) which non-linear tools are appropriate to quantify 
movement variability, and 
(iii) what are the strengths and weaknesses of 
nonlinear analysis methods with real-world data.
It can then be concluded that little research has been done 
on the effects with Reconstructed State Spaces (RSSs), Recurrent Plots (RPs), 
and Recurrence Quantification Analysis (RQA) metrics for different 
embedding parameters, different recurrence thresholds and different 
characteristics of time series (window length size, smoothness and structure).
That said, nonlinear analysis methods such as estimation of 
embedding parameters, RSSs, RPs, and RQAs are 
reviewed in the following chapter.

